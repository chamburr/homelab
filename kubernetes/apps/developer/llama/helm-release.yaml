---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: llama
  namespace: developer
spec:
  interval: 15m
  chart:
    spec:
      chart: app-template
      version: 2.6.0
      sourceRef:
        kind: HelmRepository
        name: bjw-s
        namespace: flux-system
  install:
    remediation:
      retries: 3
  upgrade:
    remediation:
      retries: 3
  values:
    global:
      nameOverride: llama
    controllers:
      main:
        containers:
          main:
            image:
              repository: ghcr.io/open-webui/open-webui
              tag: latest@sha256:9c90b1505b9cea51cda075883aa336d29e28986af958c1d3646a39fbcd07adbf
            env:
              ENABLE_SIGNUP: false
              OLLAMA_API_BASE_URL: http://llama-api.developer:11434/api
            args:
              - /bin/bash
              - -c
              - >-
                sed -i 's/r = None/r = None\n    if body:\n        body = body.decode("utf-8")
                \n        if "\\\"options\\\\":{}" in body:\n            body =
                body.replace("\\\"options\\\":{",
                "\\\"keep_alive\\\":-1,\\\"options\\\":{\\\"num_thread\\\":12")\n        elif
                "\\\"options\\\":{" in body:\n            body = body.replace("\\\"options\\\":{",
                "\\\"keep_alive\\\":-1,\\\"options\\\":{\\\"num_thread\\\":12,")\n        elif
                "\\\"model\\\":" in body:\n            body = body.replace("\\\"model\\\":",
                "\\\"keep_alive\\\":-1,\\\"options\\\":{\\\"num_thread\\\":12},\\\"model\\\":")
                \n        body = body.encode("utf-8")/' /app/backend/apps/ollama/main.py &&
                /app/backend/start.sh
    service:
      main:
        ports:
          http:
            port: 8080
    ingress:
      main:
        enabled: true
        className: traefik
        hosts:
          - host: llama.${DOMAIN}
            paths:
              - path: /
                pathType: Prefix
                service:
                  name: main
                  port: http
        tls:
          - hosts:
              - llama.${DOMAIN}
    persistence:
      config:
        enabled: true
        existingClaim: llama-data
        globalMounts:
          - path: /app/backend/data
  valuesFrom:
    - kind: Secret
      name: llama-secret
      valuesKey: secret
      targetPath: controllers.main.containers.main.env.WEBUI_SECRET_KEY
